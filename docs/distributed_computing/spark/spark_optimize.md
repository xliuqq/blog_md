# Spark 调优



## 数据倾斜

 数据倾斜只会发生在shuffle过程中

### 定位

- 在WebUI上，查看stage各个task分配的数据量；
- 根据stage，确定对应的源码位置；

### 解决

分析***key的数据分布情况***

- 预先处理（一次处理，多次使用的场景）：将数据提前预处理（仍然有数据倾斜问题），得到的结果数据，不需要再使用shuffle；

- **两阶段聚合（局部聚合+全局聚合）**：针对单次使用的场景，仅仅适用于聚合类的shuffle操作（不适合join）
  - 将原本相同的key通过附加随机前缀的方式，变成多个不同的key；





## 相关参数调优

### spark.shuffle.file.buffer

- 默认值：32k
- 参数说明：该参数用于设置shuffle write task的**BufferedOutputStream的buffer**缓冲大小。将数据写到磁盘文件之前，会先写入buffer缓冲中，待缓冲写满之后，才会溢写到磁盘。
- 调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如64k），从而减少shuffle write过程中溢写磁盘文件的次数，也就可以减少磁盘IO次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。

### spark.reducer.maxSizeInFlight

- 默认值：48m
- 参数说明：该参数用于设置**shuffle read task**的buffer缓冲大小，而这个buffer缓冲**决定了每次能够拉取多少数据**。
- 调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有1%~5%的提升。

### spark.shuffle.io.maxRetries

- 默认值：3
- 参数说明：shuffle read task从shuffle write task所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果**在指定次数之内拉取还是没有成功，就可能会导致作业执行失败**。
- 调优建议：对于那些包含了特别耗时的shuffle操作的作业，建议增加重试最大次数（比如60次），以避免由于JVM的full gc或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的shuffle过程，调节该参数可以大幅度提升稳定性。

### spark.shuffle.io.retryWait

- 默认值：5s
- 参数说明：具体解释同上，该参数代表了每次重试拉取数据的等待间隔，默认是5s。
- 调优建议：建议加大间隔时长（比如60s），以增加shuffle操作的稳定性。

### spark.shuffle.sort.bypassMergeThreshold

- 默认值：200
- 参数说明：如果shuffle read task的数量小于这个阈值（默认是200）且没有map端聚合，则**shuffle write过程中不会进行排序操作**，而是直接按照未经优化的HashShuffleManager的方式去写数据，但是最后会将每个task产生的所有临时磁盘文件都合并成一个文件，并会创建单独的索引文件。
- 调优建议：当你使用SortShuffleManager时，如果的确不需要排序操作，那么建议将这个参数调大一些，大于shuffle read task的数量。那么此时就会自动启用bypass机制，map-side就不会进行排序，减少了排序的性能开销。但是这种方式下，依然会产生大量的磁盘文件，因此shuffle write性能有待提高。



