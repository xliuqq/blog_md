# Transformer



## self-attentionæ¨¡å‹

**sequence-to-sequence è¿ç®—**ï¼š è¾“å…¥ä¸€ä¸ªå‘é‡åºåˆ—ï¼ˆa sequence of vectorsï¼‰ï¼Œè¾“å‡ºå¦ä¸€ä¸ªå‘é‡åºåˆ—



<img src="pics/self-attention.png" alt="img" style="zoom:67%;" />



**self-attention æœ¬èº«æ˜¯ä¸å…³å¿ƒè¾“å…¥çš„é¡ºåºå±æ€§çš„**



### åŸºç¡€ç‰ˆå®ç°

**æœ€åŸºç¡€çš„ self-attention æ¨¡å‹**çš„å®ç°ï¼š **ä¸¤æ¬¡çŸ©é˜µä¹˜æ³•å’Œä¸€æ¬¡å½’ä¸€åŒ–**ï¼ˆsoftmaxï¼‰ã€‚

- è¾“å…¥ **X** ç”± t ä¸ª k-ç»´ vector ç»„æˆçš„åºåˆ—ï¼Œ
- å¼•å…¥ä¸€ä¸ª minibatch dimension bï¼Œ

å°±å¾—åˆ°äº†ä¸€ä¸ªä¸‰ç»´çŸ©é˜µ `(b,t,k)`ï¼Œè¿™å°±æ˜¯ä¸€ä¸ª tensorã€‚

- è¾“å‡ºçŸ©é˜µ **Y** å°±æ˜¯ size `(b, t, k)` çš„ tensorï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯å¯¹ ğ— çš„è¡Œçš„åŠ æƒã€‚

```python
import torch
import torch.nn.functional as F

# å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº› tensor x ä½œä¸ºè¾“å…¥ï¼Œå®ƒæ˜¯ (b, t, k) ç»´çŸ©é˜µ
x = ...

# torch.bmm() æ˜¯æ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼ˆbatched matrix multiplicationï¼‰å‡½æ•°ï¼Œå¯¹ä¸€æ‰¹çŸ©é˜µæ‰§è¡Œä¹˜æ³•æ“ä½œ
raw_weights = torch.bmm(x, x.transpose(1, 2))
weights = F.softmax(raw_weights, dim=2)
y = torch.bmm(weights, x)
```



### ç°ä»£ transformer å¯¹ self-attention çš„æ‰©å±•

